{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41761ae0-99a5-4bac-bba9-74c7a8aa0d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlx_whisper\n",
    "#from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import time  # デモ用（実際の処理の進行が分かるようにするため）\n",
    "\n",
    "# -------------------------\n",
    "# 1. 音声ファイルから文字起こし\n",
    "# -------------------------\n",
    "print(\"📢 文字起こしを開始します...\")\n",
    "\n",
    "# tqdm を使用して進捗表示（デモ用）\n",
    "for _ in tqdm(range(3), desc=\"音声処理中...\"):\n",
    "    time.sleep(1)  # 実際の処理時間の代わりにスリープを挿入\n",
    "\n",
    "# 音声ファイルのパス\n",
    "audio_data = 'test_recording.m4a'\n",
    "\n",
    "# 専門用語・固有名詞のカスタムプロンプト\n",
    "custom_prompt = (\n",
    "    \"以下の専門用語・固有名詞は必ず下記の表記で文字起こししてください。\\n\"\n",
    "    \"・『AI』は『エーアイ』\\n\"\n",
    "    \"・『Deep Learning』は『ディープラーニング』\\n\"\n",
    "    \"・『GPT』は『ジーピーティー』\\n\"\n",
    ")\n",
    "\n",
    "# 文字起こし実行\n",
    "result = mlx_whisper.transcribe(\n",
    "    audio_data,\n",
    "    path_or_hf_repo=\"mlx-community/whisper-large-v3-mlx\",\n",
    "    prompt=custom_prompt\n",
    ")\n",
    "\n",
    "# **文の整形処理**\n",
    "def format_text(text):\n",
    "    import re\n",
    "    text = re.sub(r\"([。！？])\", r\"\\1\\n\", text)  # 句読点で改行\n",
    "    text = re.sub(r\"、\", \"、 \", text)  # 読点の後にスペースを入れる\n",
    "    return text.strip()\n",
    "transcription_text = result['text']\n",
    "# 文字起こし結果を保存\n",
    "with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(transcription_text)\n",
    "\n",
    "print(\"✅ 文字起こしが完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. 文字起こし結果の要約\n",
    "# -------------------------\n",
    "print(\"📄 要約を作成中...\")\n",
    "\n",
    "# tqdm を使用して進捗表示\n",
    "for _ in tqdm(range(3), desc=\"要約処理中...\"):\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# モデルのパスを指定（事前にダウンロードしたローカルパス）\n",
    "model_path = \"./models/bart-large-cnn\"\n",
    "\n",
    "# トークナイザーとモデルのロード\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# 要約用パイプラインを作成（local_files_only は削除）\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 要約実行\n",
    "summary_result = summarizer(transcription_text, max_length=150, min_length=40, do_sample=False)\n",
    "summary_text = summary_result[0]['summary_text']\n",
    "\n",
    "# 要約結果を保存\n",
    "with open(\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"✅ 要約が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. 英語翻訳（文字起こし結果・要約）\n",
    "# -------------------------\n",
    "print(\"🌍 英語翻訳を開始します...\")\n",
    "\n",
    "# tqdm を使用して進捗表示\n",
    "for _ in tqdm(range(3), desc=\"翻訳処理中...\"):\n",
    "    time.sleep(1)\n",
    "\n",
    "# 翻訳パイプライン\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"Helsinki-NLP/opus-mt-ja-en\"\n",
    ")\n",
    "\n",
    "# 文字起こし結果の英語翻訳\n",
    "english_transcription = translator(transcription_text, max_length=512)[0]['translation_text']\n",
    "with open(\"transcription_en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(english_transcription)\n",
    "\n",
    "# 要約結果の英語翻訳\n",
    "english_summary = translator(summary_text, max_length=512)[0]['translation_text']\n",
    "with open(\"summary_en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(english_summary)\n",
    "\n",
    "print(\"✅ 英語翻訳が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. o3用プロンプト付き文書の作成\n",
    "# -------------------------\n",
    "print(\"📑 o3用のプロンプト付き文書を作成中...\")\n",
    "\n",
    "o3_prompt = (\n",
    "    \"以下は論文のアイデアの音声ファイルから文字起こしした内容です。\\n\"\n",
    "    \"内容について、o3の視点から意見や改善点を教えてください。\\n\\n\"\n",
    ")\n",
    "o3_document = o3_prompt + transcription_text\n",
    "\n",
    "# o3用文書を保存\n",
    "with open(\"o3_prompt_document.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(o3_document)\n",
    "\n",
    "print(\"✅ o3用の文書作成が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 完了メッセージ\n",
    "# -------------------------\n",
    "print(\"🎉 すべての処理が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda469d3-c27c-47c9-9681-e10f0fe8b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eead2e-0481-42be-93c1-8acc6a0a834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e748d9a9-7750-49c1-8436-d06656932ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 文字起こしを開始します...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d521a5262d94766bf25a4bf32f09010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "音声処理中...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 文字起こしが完了しました。\n",
      "📄 要約を作成中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cc76f24dc341839f2b8addb9ce33ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "要約処理中...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 要約が完了しました。\n",
      "🌍 英語翻訳を開始します...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281e71be6f4f4c8ca5e038a181041625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "翻訳処理中...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hajime/Library/Caches/pypoetry/virtualenvs/whisper-meeting-TBf8Z80e-py3.12/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use mps:0\n",
      "Your input_length: 510 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 英語翻訳が完了しました。\n",
      "📑 o3用のプロンプト付き文書を作成中...\n",
      "✅ o3用の文書作成が完了しました。\n",
      "🎉 すべての処理が完了しました！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import mlx_whisper\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "\n",
    "# 出力フォルダの作成\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# -------------------------\n",
    "# 1. 音声ファイルから文字起こし\n",
    "# -------------------------\n",
    "print(\"📢 文字起こしを開始します...\")\n",
    "\n",
    "for _ in tqdm(range(3), desc=\"音声処理中...\"):\n",
    "    time.sleep(1)\n",
    "\n",
    "# 音声ファイルのパス\n",
    "audio_data = \"test_recording.m4a\"\n",
    "\n",
    "\n",
    "# 専門用語・固有名詞リストをファイルから読み込む\n",
    "def load_custom_terms(file_path):\n",
    "    terms = []\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if \",\" in line:\n",
    "                    original, replacement = line.strip().split(\",\")\n",
    "                    terms.append(f\"・『{original.strip()}』は『{replacement.strip()}』\")\n",
    "    return \"\\n\".join(terms)\n",
    "\n",
    "\n",
    "# カスタムプロンプトを作成\n",
    "terms_file = \"custom_terms.txt\"\n",
    "custom_terms = load_custom_terms(terms_file)\n",
    "\n",
    "custom_prompt = (\n",
    "    \"以下の専門用語・固有名詞は必ず下記の表記で文字起こししてください。\\n\"\n",
    "    + custom_terms\n",
    ")\n",
    "\n",
    "# 文字起こし実行\n",
    "result = mlx_whisper.transcribe(\n",
    "    audio_data,\n",
    "    path_or_hf_repo=\"mlx-community/whisper-large-v3-mlx\",\n",
    "    prompt=custom_prompt,\n",
    ")\n",
    "\n",
    "\n",
    "# **文の整形処理**\n",
    "def format_text(text):\n",
    "    import re\n",
    "\n",
    "    text = re.sub(r\"([。！？])\", r\"\\1\\n\", text)  # 句読点で改行\n",
    "    text = re.sub(r\"、\", \"、 \", text)  # 読点の後にスペースを入れる\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "transcription_text = format_text(result[\"text\"])\n",
    "\n",
    "# 文字起こし結果を保存\n",
    "\n",
    "# 文字起こし結果を保存\n",
    "transcription_path = os.path.join(output_dir, \"transcription.txt\")\n",
    "with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(transcription_text)\n",
    "\n",
    "print(\"✅ 文字起こしが完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. 文字起こし結果の要約\n",
    "# -------------------------\n",
    "print(\"📄 要約を作成中...\")\n",
    "\n",
    "for _ in tqdm(range(3), desc=\"要約処理中...\"):\n",
    "    time.sleep(1)\n",
    "\n",
    "summarizer_path = \"./models/bart-large-cnn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(summarizer_path, local_files_only=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_path, local_files_only=True)\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "summary_result = summarizer(\n",
    "    transcription_text, max_length=150, min_length=40, do_sample=False\n",
    ")\n",
    "summary_text = format_text(summary_result[0][\"summary_text\"])\n",
    "\n",
    "summary_path = os.path.join(output_dir, \"summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"✅ 要約が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. 英語翻訳（文字起こし結果・要約）\n",
    "# -------------------------\n",
    "# -------------------------\n",
    "# 3. 英語翻訳（文字起こし結果・要約）\n",
    "# -------------------------\n",
    "print(\"🌍 英語翻訳を開始します...\")\n",
    "\n",
    "# tqdm を使用して進捗表示\n",
    "for _ in tqdm(range(3), desc=\"翻訳処理中...\"):\n",
    "    time.sleep(1)\n",
    "\n",
    "# 翻訳パイプライン\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ja-en\")\n",
    "\n",
    "# 文字起こし結果の英語翻訳\n",
    "english_transcription = translator(transcription_text, max_length=512)[0][\n",
    "    \"translation_text\"\n",
    "]\n",
    "# with open(\"transcription_en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    f.write(english_transcription)\n",
    "\n",
    "translation_en_path = os.path.join(output_dir, \"translation_en.txt\")\n",
    "with open(translation_en_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(english_transcription)\n",
    "\n",
    "# 要約結果の英語翻訳\n",
    "english_summary = translator(summary_text, max_length=512)[0][\"translation_text\"]\n",
    "# with open(\"summary_en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    f.write(english_summary)\n",
    "\n",
    "summary_en_path = os.path.join(output_dir, \"summary_en.txt\")\n",
    "with open(summary_en_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(english_summary)\n",
    "\n",
    "print(\"✅ 英語翻訳が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. o3用プロンプト付き文書の作成\n",
    "# -------------------------\n",
    "print(\"📑 o3用のプロンプト付き文書を作成中...\")\n",
    "\n",
    "o3_prompt = (\n",
    "    \"以下は論文のアイデアの音声ファイルから文字起こしした内容です。\\n\"\n",
    "    \"内容について、o3の視点から意見や改善点を教えてください。\\n\\n\"\n",
    ")\n",
    "o3_document = o3_prompt + transcription_text\n",
    "\n",
    "# o3用文書を保存\n",
    "o3_prompt_path = os.path.join(output_dir, \"o3_prompt_document.txt\")\n",
    "with open(o3_prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(o3_document)\n",
    "\n",
    "print(\"✅ o3用の文書作成が完了しました。\")\n",
    "\n",
    "# -------------------------\n",
    "# 完了メッセージ\n",
    "# -------------------------\n",
    "print(\"🎉 すべての処理が完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f573e-84b4-46b6-b34a-77fc16aecdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
